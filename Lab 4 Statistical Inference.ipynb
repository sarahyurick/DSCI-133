{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The %... is an iPython thing, and is not part of the Python language.\n",
    "# In this case we're just telling the plotting library to draw things on\n",
    "# the notebook, instead of on a separate window.\n",
    "%matplotlib inline\n",
    "# See all the \"as ...\" contructs? They're just aliasing the package names.\n",
    "# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 400)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "plt.rc('figure', figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Coin toss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def throw_a_coin(N): # Use this function a simulate coin toss\n",
    "    return np.random.choice(['H','T'], size=N)  # np.random.choice choose from [H, T] with replacement N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throws=throw_a_coin(40)\n",
    "print \"Throws:\", throws\n",
    "print \"Number of Heads:\", np.sum(throws=='H')\n",
    "print \"p1 = Number of Heads/Total Throws:\", np.sum(throws=='H')/40."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do more trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials=[10, 20, 50, 70, 100, 200, 500, 800, 1000, 2000, 5000, 7000, 10000]\n",
    "plt.plot(trials, [np.sum(throw_a_coin(j)=='H')/np.float(j) for j in trials], 'o-', alpha=0.6);\n",
    "plt.xscale(\"log\")\n",
    "plt.axhline(0.5, 0, 1, color='r');\n",
    "plt.xlabel('number of trials');\n",
    "plt.ylabel('probability of heads from simulation');\n",
    "plt.title('frequentist probability of heads');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bernoulli Random Variables (in scipy.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bernoulli\n",
    "#bernoulli random variable\n",
    "brv=bernoulli(p=0.3)\n",
    "brv.rvs(size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A complete list of this bernoilli random variable object:\n",
    "```python\n",
    "\n",
    "rvs(p, loc=0, size=1, random_state=None)\tRandom variates.\n",
    "pmf(x, p, loc=0)\tProbability mass function.\n",
    "logpmf(x, p, loc=0)\tLog of the probability mass function.\n",
    "cdf(x, p, loc=0)\tCumulative distribution function.\n",
    "logcdf(x, p, loc=0)\tLog of the cumulative distribution function.\n",
    "sf(x, p, loc=0)\tSurvival function (also defined as 1 - cdf, but sf is sometimes more accurate).\n",
    "logsf(x, p, loc=0)\tLog of the survival function.\n",
    "ppf(q, p, loc=0)\tPercent point function (inverse of cdf — percentiles).\n",
    "isf(q, p, loc=0)\tInverse survival function (inverse of sf).\n",
    "stats(p, loc=0, moments='mv')\tMean(‘m’), variance(‘v’), skew(‘s’), and/or kurtosis(‘k’).\n",
    "entropy(p, loc=0)\t(Differential) entropy of the RV.\n",
    "expect(func, args=(p,), loc=0, lb=None, ub=None, conditional=False)\tExpected value of a function (of one argument) with respect to the distribution.\n",
    "median(p, loc=0)\tMedian of the distribution.\n",
    "mean(p, loc=0)\tMean of the distribution.\n",
    "var(p, loc=0)\tVariance of the distribution.\n",
    "std(p, loc=0)\tStandard deviation of the distribution.\n",
    "interval(alpha, p, loc=0)\tEndpoints of the range that contains alpha percent of the distribution\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulli.stats(0.5, loc=2, moments='m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can have a look at the distribution of the variates generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=brv.rvs(size=100)\n",
    "weights = np.ones_like(a)/float(len(a))\n",
    "plt.hist(a, weights=weights)\n",
    "# hist function doesn't provide automatic normalizing frequency to percentage, but you can achieve it by setting weights\n",
    "# It's a trick I found on Stackoverflow\n",
    "plt.xlim(-1,2)\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Another way of visualizing pmf, use bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_space=[0,1]\n",
    "plt.figure(figsize=(12,8))\n",
    "colors=sns.color_palette()\n",
    "\n",
    "for i, p in enumerate([0.1, 0.2, 0.5, 0.7]):\n",
    "    ax = plt.subplot(1, 4, i+1)\n",
    "    plt.bar(event_space, bernoulli.pmf(event_space, p), label=p, color=colors[i], alpha=0.5)\n",
    "    plt.plot(event_space, bernoulli.cdf(event_space, p), color=colors[i], alpha=0.5)\n",
    "\n",
    "    ax.xaxis.set_ticks(event_space)\n",
    "   \n",
    "    plt.ylim((0,1))\n",
    "    plt.legend(loc=0)\n",
    "    if i == 0:\n",
    "        plt.ylabel(\"PDF at $k$\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Distibution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "r=uniform.rvs(size=1000) #generates uniformly distributed variables in [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r, histtype='stepfilled', alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial distribution\n",
    "has two parameters n and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "plt.figure(figsize=(12,6))\n",
    "k = np.arange(0, 200)\n",
    "for p, color in zip([0.1, 0.3, 0.7, 0.7, 0.9], colors):\n",
    "    rv = binom(200, p)\n",
    "    plt.plot(k, rv.pmf(k), '.', lw=2, color=color, label=p)\n",
    "    plt.fill_between(k, rv.pmf(k), color=color, alpha=0.5)\n",
    "q=plt.legend()\n",
    "plt.title(\"Binomial distribution\")\n",
    "plt.tight_layout()\n",
    "q=plt.ylabel(\"PDF at $k$\")\n",
    "q=plt.xlabel(\"$k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The various ways to get random numbers\n",
    "* ``np.random.choice`` chooses items randomly from an array, with or without replacement\n",
    "* ``np.random.random`` gives us uniform randoms on [0.0,1.0)\n",
    "* ``np.random.randint`` gives us random integers in some range.\n",
    "* ``np.random.randn`` gives us random samples from a Normal distribution.\n",
    "* ``scipy.stats.distrib`` gives us stuff from a distribution. Here distrib could be binom for example, as above. distrib.pdf or distrib.pmf give us the density or mass function, while cdf gives us the cumulaive distribution function. Just using distrib as a function with its params creates a random variable generating object, from which random variables can be generated in the form distrib(params).rvs(size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import expon\n",
    "xpts=np.arange(-2,3,0.1)\n",
    "plt.plot(xpts,expon.pdf(xpts, scale=1./2.),'o')\n",
    "plt.hist(expon.rvs(size=1000, scale=1./2.), normed=True, alpha=0.5, bins=30);\n",
    "plt.xlabel(\"x\")\n",
    "plt.title(\"exponential pdf and samples(normalized)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform hypothesis testing\n",
    "### example: z-test\n",
    " Many frequentist methods for hypothesis testing roughly involve the following steps:\n",
    "\n",
    "1. Writing down the hypotheses, notably the **null hypothesis** which is the *opposite* of the hypothesis you want to prove (with a certain degree of confidence).\n",
    "2. Computing a **test statistics**, a mathematical formula depending on the test type, the model, the hypotheses, and the data.\n",
    "3. Using the computed value to accept the hypothesis, reject it, or fail to conclude.\n",
    "  \n",
    "Here, we flip a coin $n$ times and we observe $h$ heads. We want to know whether the coin is fair (null hypothesis). This example is extremely simple yet quite good for pedagogical purposes. \n",
    "\n",
    "* Let's suppose that, after $n=100$ flips, we get $h=61$ heads. We choose a significance level of 0.05: is the coin fair or not? Our null hypothesis is: *the coin is fair* ($q = 1/2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100  # number of coin flips\n",
    "h = 61  # number of heads\n",
    "q = .5  # null-hypothesis of fair coin\n",
    "\n",
    "xbar = float(h)/n #sample mean\n",
    "\n",
    "# Compute the z-score\n",
    "z = (xbar - q) * np.sqrt(n / (q*(1-q)));\n",
    "print 'z=', z\n",
    "\n",
    "# Compute p-value\n",
    "pval = 2 * (1 - sp.stats.norm.cdf(z)); pval\n",
    "print 'pval=', pval\n",
    "\n",
    "# Conclude\n",
    "print(\"Null hypothesis is rejected\" if pval < 0.05 else \"Null hypothesis is not rejected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bootstrap\n",
    "Bootstrap tries to approximate our sampling distribution. If we knew the true parameters of the population, we could generate M fake datasets. Then we could compute the parameter (or another estimator) on each one of these, to get a empirical sampling distribution of the parameter or estimator, and which will give us an idea of how typical our sample is, and thus, how good our parameter estimations from our sample are. (again from murphy)\n",
    "\n",
    "But we dont have the true parameter. So we generate these samples, using the parameter we calculated. Or, alteratively, we sample with replacement the X from our original sample D, generating many fake datasets, and then compute the distribution on the parameters as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data set of the record of new-born babies:\n",
    "\n",
    "Forty-four babies -- a new record -- were born in one 24-hour period at the Mater Mothers' Hospital in Brisbane, Queensland, Australia, on December 18, 1997. For each of the 44 babies, The Sunday Mail recorded the time of birth, the sex of the child, and the birth weight in grams. Also included is the number of minutes since midnight for each birth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"babyboom.dat.txt\", header=None, sep='\\s+', \n",
    "                   names=['24hrtime','sex','weight','minutes'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know it may be well-fitted in a poisson distribution. In this case, the time difference of new-born babies may be well modeled by a exponential ditribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timediffs = df.minutes.diff()[1:] #extract the time difference\n",
    "print timediffs\n",
    "timediffs.hist(bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-parametric Bootstrap\n",
    "Then we do bootstrapping to estimate the average time difference of birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples\n",
    "M_samples=10000\n",
    "\n",
    "# The size of each sample\n",
    "N_points = timediffs.shape[0]\n",
    "\n",
    "#Use np.random.choice to do bootstrap\n",
    "bs_np = np.random.choice(timediffs, size=(M_samples, N_points))\n",
    "\n",
    "#Calculate statistics\n",
    "sd_mean=np.mean(bs_np, axis=1)\n",
    "sd_std=np.std(bs_np, axis=1)\n",
    "\n",
    "plt.hist(sd_mean, bins=30, normed=True, alpha=0.5,label=\"samples\");\n",
    "\n",
    "# Do a kernel density estimation of the sampled means (smooth)\n",
    "sns.kdeplot(sd_mean, label=\"inferred distribution\")\n",
    "plt.axvline(timediffs.mean(), 0, 1, color='r', label='Our Sample')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametric bootstrap\n",
    "We can also do it in a parametric way. We first estimate lambda from the sample mean, and then generate many samples from the exponential distribution that's defined by the lambda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_from_mean = 1./timediffs.mean()\n",
    "rv = expon(scale=1./lambda_from_mean)\n",
    "M_samples=10000\n",
    "N_points = timediffs.shape[0]\n",
    "bs_p = rv.rvs(size=(M_samples, N_points))\n",
    "sd_mean_p=np.mean(bs_p, axis=1)\n",
    "sd_std_p=np.std(bs_p, axis=1)\n",
    "plt.hist(sd_mean_p, bins=30, normed=True, alpha=0.5);\n",
    "sns.kdeplot(sd_mean_p);\n",
    "plt.axvline(timediffs.mean(), 0, 1, color='r', label='Our Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
